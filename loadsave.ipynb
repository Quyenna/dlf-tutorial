{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalabframework\n",
    "\n",
    "The datalabframework is a productivity framework for ETL, ML application. Simplifying some of the common activities which are typical in Data pipeline such as project scaffolding, data ingesting, start schema generation, forecasting etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created SparkEngine\n",
      "Init engine \"spark\"\n",
      "Configuring packages:\n",
      "  -  com.microsoft.sqlserver:mssql-jdbc:6.4.0.jre8\n",
      "  -  com.oracle.jdbc:ojdbc8:12.2.0.1\n",
      "  -  mysql:mysql-connector-java:8.0.12\n",
      "  -  org.apache.hadoop:hadoop-aws:3.1.1\n",
      "  -  org.postgresql:postgresql:42.2.5\n",
      "  -  ru.yandex.clickhouse:clickhouse-jdbc:0.1.54\n",
      "Configuring repositories:\n",
      "  -  http://maven.icm.edu.pl/artifactory/repo/\n",
      "  -  https://maven.xwiki.org/externals\n",
      "Configuring conf:\n",
      "  -  spark.hadoop.fs.s3a.access.key : ****** (redacted)\n",
      "  -  spark.hadoop.fs.s3a.endpoint : http://minio:9000\n",
      "  -  spark.hadoop.fs.s3a.impl : org.apache.hadoop.fs.s3a.S3AFileSystem\n",
      "  -  spark.hadoop.fs.s3a.path.style.access : true\n",
      "  -  spark.hadoop.fs.s3a.secret.key : ****** (redacted)\n",
      "Connecting to spark master: local[1]\n",
      "Engine context spark:2.4.1 successfully started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<datalabframework.project.Project at 0x7f80e5319f98>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.project.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal(a,b):\n",
    "    cnt = a.exceptAll(b).count() + b.exceptAll(a).count()\n",
    "    return cnt==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local files\n",
    "\n",
    "The following show some load/save round trip on the local file system using various formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|  a|  b|   c|\n",
      "+---+---+----+\n",
      "|yes|  1|1.41|\n",
      "| no|  0|3.14|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "df = dlf.engine().load('data/examples/sample.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save in various format\n",
    "dlf.save(df, 'data/save/foo.csv')\n",
    "dlf.save(df, 'data/save/foo.json')\n",
    "dlf.save(df, 'data/save/foo.parquet')\n",
    "\n",
    "# with various compression\n",
    "dlf.save(df, 'data/save/foo.json.bz2')\n",
    "dlf.save(df, 'data/save/foo.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using format specific save\n",
    "\n",
    "dlf.save(df, 'data/save/bar.1', format='csv')\n",
    "dlf.save(df, 'data/save/bar.2', format='json')\n",
    "dlf.save(df, 'data/save/bar.3', format='parquet')\n",
    "\n",
    "# with various compression\n",
    "dlf.save(df, 'data/save/bar.4', format='csv', compression='bzip2')\n",
    "dlf.save(df, 'data/save/bar.5', format='json', compression='gzip')\n",
    "dlf.save(df, 'data/save/bar.6', format='parquet', compression='gzip')\n",
    "dlf.save(df, 'data/save/bar.7', format='parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round trip reading\n",
    "df_tst = dlf.load('data/save/foo.csv')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/foo.json')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/foo.parquet')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/foo.json.bz2')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/foo.csv.gz')\n",
    "assert(equal(df,df_tst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round trip reading (format specific load)\n",
    "df_tst = dlf.load('data/save/bar.1', format='csv')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/bar.2', format='json')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/bar.3', format='parquet')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "# df_tst = dlf.load('data/save/bar.4', format='csv', compression='bzip2')\n",
    "# assert(equal(df,df_tst))\n",
    "\n",
    "# df_tst = dlf.load('data/save/bar.5', format='json', compression='gzip')\n",
    "# assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/bar.6', format='parquet', compression='gzip')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/save/bar.7', format='parquet', compression='snappy')\n",
    "assert(equal(df,df_tst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from HDFS\n",
    "\n",
    "We can override the default resource provider, \n",
    "by explicitely passing a different provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.save(df, 'data/examples/bar.csv', 'hdfs')\n",
    "dlf.save(df, 'data/examples/bar.json', 'hdfs')\n",
    "dlf.save(df, 'data/examples/bar.parquet', 'hdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst = dlf.load('data/examples/bar.csv', 'hdfs')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/examples/bar.json', 'hdfs')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/examples/bar.parquet', 'hdfs')\n",
    "assert(equal(df,df_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from Minio\n",
    "\n",
    "We can override the default resource provider, \n",
    "by explicitely passing a different provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.save(df, 'data/examples/bar.csv', 'minio')\n",
    "dlf.save(df, 'data/examples/bar.json', 'minio')\n",
    "dlf.save(df, 'data/examples/bar.parquet', 'minio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst = dlf.load('data/examples/bar.csv', 'minio')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/examples/bar.json', 'minio')\n",
    "assert(equal(df,df_tst))\n",
    "\n",
    "df_tst = dlf.load('data/examples/bar.parquet', 'minio')\n",
    "assert(equal(df,df_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from Web (HTTP/HTTPS)\n",
    "\n",
    "Files from web will be first downloaded locally on the driver, then passed to spark ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/natbusa/dlf-tutorial/master/data/examples/sample.csv\n",
      "Downloaded 27 bytes\n"
     ]
    }
   ],
   "source": [
    "df_tst = dlf.load('https://raw.githubusercontent.com/natbusa/dlf-tutorial/master/data/examples/sample.csv')\n",
    "assert(equal(df,df_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data from a Database (via jdbc connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MySQL: Sakila DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|last_name|amount|\n",
      "+---------+------+\n",
      "|    ABNEY|    21|\n",
      "|     ADAM|    28|\n",
      "|    ADAMS|    27|\n",
      "|ALEXANDER|    27|\n",
      "|   ALLARD|    32|\n",
      "|    ALLEN|    31|\n",
      "|  ALVAREZ|    27|\n",
      "| ANDERSON|    24|\n",
      "|   ANDREW|    25|\n",
      "|  ANDREWS|    23|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT c.last_name,\n",
    "        COUNT(p.amount) AS amount\n",
    "    FROM customer c\n",
    "    LEFT JOIN payment p\n",
    "        ON c.customer_id = p.customer_id\n",
    "    WHERE c.last_name like 'A%'\n",
    "    GROUP BY  c.last_name\n",
    "    ORDER BY  c.last_name ASC\n",
    "    LIMIT 10;\n",
    "\"\"\"\n",
    "dlf.load(query, 'sakila').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|customer_id|store_id|first_name|last_name|               email|address_id|active|        create_date|        last_update|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|          1|       1|      MARY|    SMITH|MARY.SMITH@sakila...|         5|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          2|       1|  PATRICIA|  JOHNSON|PATRICIA.JOHNSON@...|         6|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          3|       1|     LINDA| WILLIAMS|LINDA.WILLIAMS@sa...|         7|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          4|       2|   BARBARA|    JONES|BARBARA.JONES@sak...|         8|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          5|       1| ELIZABETH|    BROWN|ELIZABETH.BROWN@s...|         9|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlf.load('customer', 'sakila').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----------+---------+\n",
      "|customer_id|store_id|first_name|last_name|\n",
      "+-----------+--------+----------+---------+\n",
      "|          1|       1|      MARY|    SMITH|\n",
      "|          2|       1|  PATRICIA|  JOHNSON|\n",
      "|          3|       1|     LINDA| WILLIAMS|\n",
      "|          4|       2|   BARBARA|    JONES|\n",
      "|          5|       1| ELIZABETH|    BROWN|\n",
      "|          6|       2|  JENNIFER|    DAVIS|\n",
      "|          7|       1|     MARIA|   MILLER|\n",
      "|          8|       2|     SUSAN|   WILSON|\n",
      "|          9|       2|  MARGARET|    MOORE|\n",
      "|         10|       1|   DOROTHY|   TAYLOR|\n",
      "+-----------+--------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = dlf.load('customer', 'sakila')\n",
    "df.select('customer_id', 'store_id', 'first_name', 'last_name').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clickhouse: Taxes DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+---------------+--------------------+--------+\n",
      "|      total_emv|   total_tbea|      total_bav|           tax_class|tax_rate|\n",
      "+---------------+-------------+---------------+--------------------+--------+\n",
      "|      1.31511E8|    3015446.0|     2.345737E7|2a - 4-6 unit res...|12.8550%|\n",
      "|    2.3639859E8|    7038237.0|    5.4750993E7| 2c - co-op or co...|12.8550%|\n",
      "|        7.778E7|    2107258.0|    1.6392523E7|2b - 7-10 unit re...|12.8550%|\n",
      "|2.5456025934E10|1.119343167E9|1.0476817274E10|4 - commercial pr...|10.6840%|\n",
      "|      1442000.0|      72190.0|       648900.0|3 - utility property|11.1250%|\n",
      "|            0.0|    1574279.0|      1574279.0|                    |        |\n",
      "|  7.279443191E9| 3.69685076E8|  2.875808079E9| 2 - residential,...|12.8550%|\n",
      "|      1.31918E8|     979489.0|      5112968.0| 1 - small home, ...|19.1570%|\n",
      "+---------------+-------------+---------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT \n",
    "        SUM(emv) as total_emv, \n",
    "        SUM(tbea) as total_tbea, \n",
    "        SUM(bav) as total_bav, \n",
    "        tax_class,\n",
    "        tax_rate \n",
    "    FROM tax_bills_nyc \n",
    "    GROUP BY tax_class, tax_rate\n",
    "\"\"\"\n",
    "dlf.load(query, 'taxes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------+---------+--------+--------+-----+------------+-----------+-----+\n",
      "|       bbl|          owner_name|             address|           tax_class|tax_rate|      emv|    tbea|     bav|  tba|property_tax|condonumber|condo|\n",
      "+----------+--------------------+--------------------+--------------------+--------+---------+--------+--------+-----+------------+-----------+-----+\n",
      "|1001200009|DEPT OF TRANSPORT...|DEPT OF TRANSPORT...|3 - utility property|11.1250%|1442000.0| 72190.0|648900.0|     |           0|           |     |\n",
      "|1000791001|138 FULTON CREW, ...|138 FULTON CREW L...| 2c - co-op or co...|12.8550%|2441000.0| 49588.0|385746.0|49588|       49588|       1333| unit|\n",
      "|1000111001|15 STONE STREET C...|15 STONE STREET C...| 2c - co-op or co...|12.8550%|2373000.0| 41812.0|325260.0|41812|       41812|       2099| unit|\n",
      "|1000111002|15 STONE STREET C...|15 STONE STREET C...| 2c - co-op or co...|12.8550%|3242000.0| 62718.0|487890.0|36687|        7556|       2099| unit|\n",
      "|1001351706|16 WARREN STREET ...|16 WARREN STREET ...| 2c - co-op or co...|12.8550%|2140039.0|123796.0|963018.0|78602|       78602|       1940| unit|\n",
      "+----------+--------------------+--------------------+--------------------+--------+---------+--------+--------+-----+------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlf.load('tax_bills_nyc', 'taxes').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSSql: School DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------+------------+\n",
      "|CourseID|      Title|Credits|DepartmentID|\n",
      "+--------+-----------+-------+------------+\n",
      "|    1045|   Calculus|      4|           7|\n",
      "|    1050|  Chemistry|      4|           1|\n",
      "|    1061|    Physics|      4|           1|\n",
      "|    2021|Composition|      3|           2|\n",
      "|    2030|     Poetry|      2|           2|\n",
      "+--------+-----------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlf.load('course', 'school').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oracle: HR DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+-------------------+-------+--------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|          HIRE_DATE| JOB_ID|  SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+-------------------+-------+--------+--------------+----------+-------------+\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|2003-06-17 00:00:00|AD_PRES|24000.00|          null|      null|           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|2005-09-21 00:00:00|  AD_VP|17000.00|          null|       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|2001-01-13 00:00:00|  AD_VP|17000.00|          null|       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|2006-01-03 00:00:00|IT_PROG| 9000.00|          null|       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|2007-05-21 00:00:00|IT_PROG| 6000.00|          null|       103|           60|\n",
      "+-----------+----------+---------+--------+------------+-------------------+-------+--------+--------------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlf.load('employees', 'human_resources').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postgres: Pagila DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|   sum|customer_id|\n",
      "+------+-----------+\n",
      "| 90.77|        184|\n",
      "|145.70|         87|\n",
      "|109.78|        477|\n",
      "|157.65|        273|\n",
      "|159.68|        550|\n",
      "+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query from resource\n",
    "md = dlf.Resource('select CAST(sum(amount) as DECIMAL(8,2)), customer_id from payment group by customer_id', 'pagila')\n",
    "dlf.load(md).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   33489.47|  Hillyer|      Mike|\n",
      "|   33927.04| Stephens|       Jon|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use JOIN to display the total amount rung up by each staff member\n",
    "# use tables 'staff' and 'payment'\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        CAST(SUM(p.amount) AS DECIMAL(16,2)) as total_sales, \n",
    "        s.last_name, \n",
    "        s.first_name\n",
    "    FROM payment p \n",
    "    INNER JOIN staff s ON p.staff_id = s.staff_id \n",
    "    GROUP BY s.last_name, s.first_name\n",
    "    \"\"\"\n",
    "df = dlf.load(query, 'pagila')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = dlf.Resource('total_sales', 'pagila')\n",
    "dlf.save(df, md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   33489.47|  Hillyer|      Mike|\n",
      "|   33927.04| Stephens|       Jon|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# round trip read back\n",
    "df = dlf.load('total_sales', 'pagila')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalabframework 0.8.2\n"
     ]
    }
   ],
   "source": [
    "# check if the pyspark DataFrame class is monkey patched\n",
    "df.datalabframework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33489.47</td>\n",
       "      <td>Hillyer</td>\n",
       "      <td>Mike</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  total_sales last_name first_name\n",
       "0    33489.47   Hillyer       Mike"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data.collect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   12345.67|   Dereck|       Eve|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a new dataframe from the original one, \n",
    "# by providing new data and retaining the original schema\n",
    "\n",
    "from decimal import Decimal as d\n",
    "df = df.rows.overwrite([(d(12345.67),'Dereck', 'Eve')])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+\n",
      "|total_sales|last_name|first_name|\n",
      "+-----------+---------+----------+\n",
      "|   33489.47|  Hillyer|      Mike|\n",
      "|   33927.04| Stephens|       Jon|\n",
      "|   12345.67|   Dereck|       Eve|\n",
      "+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# append new records and reload\n",
    "dlf.save(df, 'total_sales', 'pagila', mode='append')\n",
    "dlf.load('total_sales', 'pagila').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From one provider to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.load('payment', 'pagila').save('data/payment', 'hdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
