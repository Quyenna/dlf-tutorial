{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalabframework\n",
    "\n",
    "The datalabframework is a productivity framework for ETL, ML application. Simplifying some of the common activities which are typical in Data pipeline such as project scaffolding, data ingesting, start schema generation, forecasting etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a project\n",
    "\n",
    "One of the main things here is to have configuration and code separated in different files. Project is all about setting the correct working directories where to run and find your notebooks, python files and configuration files. When the datalabframework project is loaded, it starts by searching for a `__main__.py` file, according to python module file naming conventions. When such a file is found, the corresponding directory is set as the root path for the project. All modules and alias paths are all relative to the project root path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the profile can be done with the `datalabframework.project.load` function call. It will look for files ending with `metadata.yml`. The function can optionally set the current working directory and import the key=values of .env file into the python os environment. if no parameters are specified, the default profile is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module datalabframework.project:\n",
      "\n",
      "load(profile='default', rootpath=None)\n",
      "    Performs the following steps:\n",
      "        - set rootdir for the given project\n",
      "        - import variables from  <rootdir>/.env (if present),\n",
      "        - load the `profile` from the metadata files\n",
      "        - setup and start the data engine\n",
      "    \n",
      "    :param profile: load the given metadata profile (default: 'default')\n",
      "    \n",
      "    :param rootpath: root directory for loaded project \n",
      "           default behaviour: search parent dirs to detect rootdir by \n",
      "           looking for a '__main__.py' or 'main.ipynb' file. \n",
      "           When such a file is found, the corresponding directory is the \n",
      "           root path for the project. If nothing is found, the current \n",
      "           working directory, will be the rootpath\n",
      "    \n",
      "    :return: None\n",
      "    \n",
      "    Notes abount metadata configuration:\n",
      "    \n",
      "    1)  Metadata files are merged up, so you can split the information in \n",
      "        multiple files as long as they end with `metadata.yml`. \n",
      "    \n",
      "        For example: `metadata.yml`, `abc.metadata.yaml`, `abc_metadata.yml` \n",
      "        are all valid metadata file names.\n",
      "    \n",
      "    2)  All metadata files in all subdirectories from the project root directory \n",
      "        are loaded, unless the directory contains a file `metadata.ignore.yml`\n",
      "    \n",
      "    3)  Metadata files can provide multiple profile configurations,\n",
      "        by separating each profile configuration with a Document Marker \n",
      "        ( a line with `---`) (see https://yaml.org/spec/1.2/spec.html#YAML)\n",
      "    \n",
      "    4)  Each metadata profile, can be broken down in multiple yaml files,\n",
      "        When loading the files all configuration belonging to the same profile \n",
      "        with be merged.\n",
      "    \n",
      "    5)  All metadata profiles inherit the settings from profile 'default'\n",
      "    \n",
      "    Metadata files are composed of 6 sections:\n",
      "        - profile\n",
      "        - variables\n",
      "        - providers\n",
      "        - resources\n",
      "        - engine\n",
      "        - loggers\n",
      "    \n",
      "    For more information about metadata configuration,\n",
      "    type `help(datalabframework.project.metadata)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dlf.project.load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function config in module datalabframework.project:\n",
      "\n",
      "config()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dlf.project.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init engine \"spark\"\n",
      "Loading detected packages:\n",
      "  -  org.apache.hadoop:hadoop-aws:3.1.1\n",
      "  -  com.microsoft.sqlserver:mssql-jdbc:6.4.0.jre8\n",
      "  -  mysql:mysql-connector-java:8.0.12\n",
      "  -  org.postgresql:postgresql:42.2.5\n",
      "Connecting to spark master: local[*]\n",
      "Engine context spark:2.4.1 successfully started\n"
     ]
    }
   ],
   "source": [
    "# Loading default profile\n",
    "project = dlf.project.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will display the configuration of the project metadata profile and configuration data loaded. The configuration is available as a dictionary object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "version: 0.7.1\n",
       "username: jovyan\n",
       "session_id: '0x51de6ac0603b11e9'\n",
       "profile: default\n",
       "rootdir: /home/jovyan/work/tutorial\n",
       "script_path: load.ipynb\n",
       "dotenv_path:\n",
       "notebooks_files:\n",
       "  - main.ipynb\n",
       "  - install.ipynb\n",
       "  - versions.ipynb\n",
       "  - metadata.ipynb\n",
       "  - project.ipynb\n",
       "  - scaffolding.ipynb\n",
       "  - logging.ipynb\n",
       "  - hello.ipynb\n",
       "  - load.ipynb\n",
       "python_files:\n",
       "  - __main__.py\n",
       "metadata_files:\n",
       "  - metadata.yml\n",
       "repository:\n",
       "    type: git\n",
       "    committer: natbusa\n",
       "    hash: 6b01799\n",
       "    commit: 6b017991f154d237345349ef7d2d4fa69fa9f8e4\n",
       "    branch: master\n",
       "    url: https://github.com/natbusa/dlf-tutorial\n",
       "    name: dlf-tutorial\n",
       "    date: '2019-04-15T10:14:10+00:00'\n",
       "    clean: false"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.project.config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a specific profile\n",
    "\n",
    "Loading explicitely a different profile.  \n",
    "In this case the profile `prod` will connect to a cluster in client mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init engine \"spark\"\n",
      "Loading detected packages:\n",
      "  -  org.apache.hadoop:hadoop-aws:3.1.1\n",
      "  -  com.microsoft.sqlserver:mssql-jdbc:6.4.0.jre8\n",
      "  -  mysql:mysql-connector-java:8.0.12\n",
      "  -  org.postgresql:postgresql:42.2.5\n",
      "Connecting to spark master: spark://spark-master:7077\n",
      "Engine context spark:2.4.1 successfully started\n"
     ]
    }
   ],
   "source": [
    "# Loading default profile\n",
    "project = dlf.project.load('prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
